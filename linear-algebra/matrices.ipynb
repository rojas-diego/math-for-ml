{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrices\n",
    "\n",
    "A matrix is a rectangular tuple of elements with $m$ rows and $n$ columns where $m, n \\in \\N$.\n",
    "\n",
    "> ðŸ’œ $\\R^{m \\times n}$ is the set of all real-valued $(m, n)$ matrices.\n",
    "\n",
    "> ðŸ’œ $A \\in \\R^{m \\times n}$ can be represented as a vector $a \\in \\R^{mn}$ by stacking all $n$ columns into a long vector.\n",
    "\n",
    "### Addition\n",
    "\n",
    "> ðŸ’œ The sum of two matrices $A \\in \\R^{m \\times n}, B \\in \\R^{m \\times n}$ is defined as an element-wise sum.\n",
    "\n",
    "### Multiplication\n",
    "\n",
    "> ðŸ’œ For matrices $A \\in \\R^{m \\times n}, B \\in \\R^{m \\times k}$, the elements $c_{ij}$ of the product $C = AB \\in \\R^{m \\times k}$ are computed as:\n",
    "> \n",
    "> $\n",
    "> c_{ij} = \\sum\\limits_{l=1}^{n} = a_{il} b_{lj}, \\text{ where } i = 1, \\dots, m, \\text{ and } j = 1, \\dots, k.\n",
    "> $\n",
    "\n",
    "> ðŸ’œ Matrix multiplication is not commutative.\n",
    "\n",
    "Thus, $c_{ij}$ is equal to the dot product of the $i$ th row of $A$ and the $j$ th column of $B$.\n",
    "\n",
    "> ðŸ’œ Element wise multiplication of $A, B \\in \\R^{m \\times n}$ is called a *Hadamard product*.\n",
    "\n",
    "### Identity matrix\n",
    "\n",
    "We define an identity matrix in $\\R^{n \\times n}$ as:\n",
    "\n",
    "$\n",
    "I_n := \\begin{bmatrix}\n",
    "    1 & \\cdots & 0 & \\cdots & 0 \\\\\n",
    "    \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & \\cdots & 1 & \\cdots & 0 \\\\\n",
    "    \\vdots & \\ddots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    0 & \\cdots & 0 & \\cdots & 1\n",
    "\\end{bmatrix} \\in \\R^{n \\times n}\n",
    "$\n",
    "\n",
    "### Associativity\n",
    "\n",
    "> ðŸ’œ $\\forall A \\in \\R^{m \\times n}, B \\in \\R^{n \\times p}, C \\in \\R^{p \\times q} \\text{ : } (AB)C = A(BC)$\n",
    "\n",
    "### Distributivity\n",
    "\n",
    "> ðŸ’œ $\\forall A, B \\in \\R^{m \\times n}, C, D \\in \\R^{n \\times p}$ :\n",
    "> \\begin{align}(A + B)C = AC + BC \\\\\n",
    "> A (C + D) = AC + AD\n",
    "> \\end{align}\n",
    "\n",
    "### Multiplication with identity matrix\n",
    "\n",
    "> ðŸ’œ $\\forall A \\in \\R^{m \\times n} : I_m A = A I_n = A$\n",
    "\n",
    "### Inverse\n",
    "\n",
    "> ðŸ’œ The inverse of a matrix $A \\in \\R^{n \\times n}$ denoted $A^{-1}$ is a unique matrix $B \\in \\R^{n \\times n}$ given $AB = I_n = BA$\n",
    "\n",
    "Unfortunately, not every matrix $A$ possesses an inverse $A^{âˆ’1}$. If this inverse does exist, $A$ is called *regular/invertible/nonsingular*, otherwise *singular/noninvertible*.\n",
    "\n",
    "### Transpose\n",
    "\n",
    "> ðŸ’œ For $A \\in \\R^{m \\times n}$ the matrix $B \\in \\R^{n \\times m}$ with $b_{ij} = a_{ji}$ is called the transpose of $A$. We write $B = A^T$\n",
    "\n",
    "> ðŸ’œ The following are important properties of inverses and transposes\n",
    "> \\begin{align}\n",
    ">   AA^{-1} &= I = A^{-1}A \\\\\n",
    ">   (AB)^{-1} &= B^{-1} A^{-1} \\\\\n",
    ">   A^TA^T &= A  \\\\\n",
    ">   (A + B)^T &= A^T + B^T \\\\\n",
    ">   (AB)^T &= A^T B^T\n",
    "> \\end{align}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
